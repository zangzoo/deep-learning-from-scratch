{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5XfJFNgUiOu1qFxJ9ixe8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 역전파, MulLayer"],"metadata":{"id":"QgJ6LJa5XM9A"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"A6OCh_d_WgT0","executionInfo":{"status":"ok","timestamp":1728814175561,"user_tz":-540,"elapsed":351,"user":{"displayName":"송여경","userId":"16440594923547462791"}}},"outputs":[],"source":["class MulLayer:\n","  def __init__(self):\n","    self.x = None\n","    self.y = None\n","\n","  def forward(self, x, y):\n","    self.x = x\n","    self.y = y\n","    out = x * y\n","    return out\n","\n","  def backward(self, dout):\n","    dx = dout * self.y\n","    dy = dout * self.x\n","    return dx, dy"]},{"cell_type":"markdown","source":["## 순전파, MulLayer"],"metadata":{"id":"o5sHeMBbXR2I"}},{"cell_type":"code","source":["apple = 100\n","apple_num = 2\n","tax = 1.1\n","\n","mul_apple_layer = MulLayer()\n","mul_tax_layer = MulLayer()\n","\n","apple_price = mul_apple_layer.forward(apple, apple_num)\n","price = mul_tax_layer.forward(apple_price, tax)\n","\n","print(price)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CcL1eUrZXV8M","executionInfo":{"status":"ok","timestamp":1728814384275,"user_tz":-540,"elapsed":4,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"3db79441-4f62-41ff-a5ef-5c0ddac305db"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["220.00000000000003\n"]}]},{"cell_type":"code","source":["dprice = 1\n","dapple_price, dtax = mul_tax_layer.backward(dprice)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n","\n","print(dapple, dapple_num, dtax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxuH1-kAWtIS","executionInfo":{"status":"ok","timestamp":1728814494850,"user_tz":-540,"elapsed":345,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"b33d2951-5e3d-4e5a-e609-362b27ae9ce2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2 110.00000000000001 200\n"]}]},{"cell_type":"markdown","source":["## 덧셈 계층"],"metadata":{"id":"YT22x-f0a4Y6"}},{"cell_type":"code","source":["class AddLayer:\n","  def __init__(self):\n","    pass\n","\n","  def forward(self, x, y):\n","    out = x + y\n","    return out\n","\n","  def backward(self, dout):\n","    dx = dout * 1\n","    dy = dout * 1\n","    return dx, dy"],"metadata":{"id":"wnK4kAIRX7Ff","executionInfo":{"status":"ok","timestamp":1728815308168,"user_tz":-540,"elapsed":3,"user":{"displayName":"송여경","userId":"16440594923547462791"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["apple = 100\n","apple_num = 2\n","orange = 150\n","orange_num = 3\n","tax = 1.1\n","\n","mul_apple_layer = MulLayer()\n","mul_orange_layer = MulLayer()\n","add_apple_orange_layer = AddLayer()\n","mul_tax_layer = MulLayer()\n","\n","apple_price = mul_apple_layer.forward(apple, apple_num)\n","orange_price = mul_orange_layer.forward(orange, orange_num)\n","all_price = add_apple_orange_layer.forward(apple_price, orange_price)\n","price = mul_tax_layer.forward(all_price, tax)\n","\n","dprice = 1\n","dall_price, dtax =  mul_tax_layer.backward(dprice)\n","dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n","dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n","\n","print(\"price\", int(price))\n","print(\"dApple\", dapple)\n","print(\"dApple_num\", int(dapple_num))\n","print(\"dOrange\", dorange)\n","print(\"dOrange_num\", int(dorange_num))\n","print(\"dTax\", dtax)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sa258pVmbBtN","executionInfo":{"status":"ok","timestamp":1728816002641,"user_tz":-540,"elapsed":412,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"26fa670f-9e81-4e2f-8d16-4af185fdf74c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["price 715\n","dApple 2.2\n","dApple_num 110\n","dOrange 3.3000000000000003\n","dOrange_num 165\n","dTax 650\n"]}]},{"cell_type":"markdown","source":["dprice = 1\n","\n","이는 최종 출력에 대한 그래디언트를 1로 설정합니다. 이는 연쇄 법칙을 적용하기 위한 시작점입니다.\n","\n","\n","dall_price, dtax = mul_tax_layer.backward(dprice)\n","\n","세금을 곱하는 층의 역전파를 수행합니다.\n","dprice(1)를 입력으로 받아, 세금을 곱하기 전 가격(all_price)에 대한 그래디언트와 세율(tax)에 대한 그래디언트를 계산합니다.\n","\n","\n","dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)\n","\n","사과와 오렌지 가격을 더하는 층의 역전파를 수행합니다.\n","dall_price를 입력으로 받아, 사과 가격과 오렌지 가격 각각에 대한 그래디언트를 계산합니다.\n","\n","\n","dorange, dorange_num = mul_orange_layer.backward(dorange_price)\n","\n","오렌지 가격을 계산하는 곱셈 층의 역전파를 수행합니다.\n","dorange_price를 입력으로 받아, 오렌지 단가와 개수 각각에 대한 그래디언트를 계산합니다.\n","\n","\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n","\n","사과 가격을 계산하는 곱셈 층의 역전파를 수행합니다.\n","dapple_price를 입력으로 받아, 사과 단가와 개수 각각에 대한 그래디언트를 계산합니다."],"metadata":{"id":"6Pv-dkHRdBBc"}},{"cell_type":"code","source":["class Relu:\n","  def __init__(self):\n","    self.mask = None\n","\n","  def forward(self, x):\n","    self.mask = (x <= 0)\n","    out = x.copy()\n","    out[self.mask] = 0\n","    return out\n","\n","  def backward(self, dout):\n","    dout[self.mask] = 0\n","    dx = dout\n","    return dx"],"metadata":{"id":"El3WaffGbFoq","executionInfo":{"status":"ok","timestamp":1728827490146,"user_tz":-540,"elapsed":426,"user":{"displayName":"송여경","userId":"16440594923547462791"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n","print(x)\n","mask = (x <= 0)\n","print(mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8k1K40bzdB5w","executionInfo":{"status":"ok","timestamp":1728827513111,"user_tz":-540,"elapsed":359,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"b61d6ef6-699e-450d-9b5e-3fc6898ec20a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.  -0.5]\n"," [-2.   3. ]]\n","[[False  True]\n"," [ True False]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGbDLQo4JlRA","executionInfo":{"status":"ok","timestamp":1728827845116,"user_tz":-540,"elapsed":365,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"e19d5770-3a6c-47c7-a164-844ed0ec4c8a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.  -0.5]\n"," [-2.   3. ]]\n","[[False  True]\n"," [ True False]]\n"]}]},{"cell_type":"markdown","source":["## Sigmoid 함수"],"metadata":{"id":"0m6u8qpuNr1y"}},{"cell_type":"code","source":["class Sigmoid:\n","    def __init__(self):\n","        self.out = None\n","\n","    def forward(self, x):\n","        out = sigmoid(x)\n","        self.out = out\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * (1.0 - self.out) * self.out\n","\n","        return dx"],"metadata":{"id":"DDe_ozmBKx5X","executionInfo":{"status":"ok","timestamp":1728828596891,"user_tz":-540,"elapsed":383,"user":{"displayName":"송여경","userId":"16440594923547462791"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# 순전파 때의 편향 덧셈\n","X_dot_W = np.array([[0,0,0], [10,10,10]])\n","B = np.array([1,2,3])\n","\n","print(X_dot_W)\n","print(X_dot_W + B)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALRFBU8fOMx4","executionInfo":{"status":"ok","timestamp":1728828729072,"user_tz":-540,"elapsed":360,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"23da2a49-b0ff-4bc8-9d71-7f39454410e7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0]\n"," [10 10 10]]\n","[[ 1  2  3]\n"," [11 12 13]]\n"]}]},{"cell_type":"code","source":["# 역전파 때의 편향 덧셈\n","dY = np.array([[1,2,3],[4,5,6]])\n","print(dY)\n","dB = np.sum(dY, axis=0)\n","print(dB)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxzykFxTNt8s","executionInfo":{"status":"ok","timestamp":1728828743164,"user_tz":-540,"elapsed":373,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"2a3d004e-c661-4811-cd99-ed22123eda7f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3]\n"," [4 5 6]]\n","[5 7 9]\n"]}]},{"cell_type":"code","source":["class Affine:\n","  def __init__(self, W, b):\n","    self.W = W\n","    self.b = b\n","    self.x = None\n","    self.dW = None\n","    self.db = None\n","\n","  def forward(self, x):\n","    self.x = x\n","    out = np.dot(x, self.W) + self.b\n","\n","    return out\n","\n","  def backward(self, dout):\n","    dx = np.dot(dout, self.W.T)\n","    self.dW = np.dot(self.x.T, dout)\n","    self.db = np.sum(dout, axis=0)\n","\n","    return dx"],"metadata":{"id":"8zOOuRBhOevN","executionInfo":{"status":"ok","timestamp":1728828798165,"user_tz":-540,"elapsed":2,"user":{"displayName":"송여경","userId":"16440594923547462791"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class SoftmaxWithLoss:\n","    def __init__(self):\n","        self.loss = None # 손실\n","        self.y = None # softmax의 출력\n","        self.t = None # 정답레이블 (원-핫 벡터)\n","\n","    def forward(self, x, t):\n","        self.t = t\n","        self.y = softmax(x)\n","        self.loss = cross_entropy_error(self.y, self.t)\n","\n","        return self.loss\n","\n","    def backward(self, dout=1):\n","        batch_size = self.t.shape[0]\n","        if self.t.size == self.y.size: # 정답레이블이 원-핫 벡터일 경우\n","            dx = (self.y - self.t) / batch_size\n","        else:\n","            dx = self.y.copy()\n","            dx[np.arange(batch_size), self.t] -= 1\n","            dx = dx / batch_size\n","\n","        return dx"],"metadata":{"id":"wRCU9RqlORqo","executionInfo":{"status":"ok","timestamp":1728828860066,"user_tz":-540,"elapsed":405,"user":{"displayName":"송여경","userId":"16440594923547462791"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["## 오차 역전파법을 이용한 신경망 구현"],"metadata":{"id":"T4RygueZO4et"}},{"cell_type":"code","source":["import sys, os\n","# Assuming deep-learning-from-scratch is in the parent directory\n","sys.path.append(os.path.abspath('../deep-learning-from-scratch/common'))\n","import numpy as np\n","from gradient import numerical_gradient\n","from collections import OrderedDict\n","\n","class TwoLayerNet:\n","\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n","        # 가중치 초기화\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","        # 계층 생성\n","        # OrderedDict = 순서가 있는 딕셔너리, 순서 기억\n","        # 순전파 때는 계층을 추가한 순서대로 / 역전파 때는 계층 반대 순서로 호출\n","        self.layers = OrderedDict()\n","        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n","        self.layers['Relu1'] = Relu()\n","        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n","\n","        self.lastLayer = SoftmaxWithLoss()\n","\n","    def predict(self, x):\n","        for layer in self.layers.values():\n","            x = layer.forward(x)\n","\n","        return x\n","\n","    # x: 입력데이터, t : 정답레이블\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        return self.lastLayer.forward(y, t)\n","\n","    def accuracy(self, x, t):\n","        y = self.predict(x)\n","        y = np.argmax(y, axis=1)\n","        if t.ndim != 1 : t = np.argmax(t, axis=1)\n","\n","        accuracy = np.sum(y == t) / float(x.shape[0])\n","        return accuracy\n","\n","    # x: 입력데이터, t : 정답레이블\n","    def numerical_gradient(self, x, t):\n","        loss_W = lambda W: self.loss(x, t)\n","\n","        grads = {}\n","        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","\n","        return grads\n","\n","    def gradient(self, x, t):\n","        # forward, 순전파\n","        self.loss(x, t)\n","\n","        # backward, 역전파\n","        dout = 1\n","        dout = self.lastLayer.backward(dout)\n","\n","        layers = list(self.layers.values())\n","        layers.reverse()\n","        for layer in layers:\n","            dout = layer.backward(dout)\n","\n","        # 결과 저장\n","        grads = {}\n","        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n","        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n","\n","        return grads"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"DLu_do1nOuMt","executionInfo":{"status":"error","timestamp":1728829063692,"user_tz":-540,"elapsed":356,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"bcb02acd-37a5-48ab-e016-f7c6acc1962c"},"execution_count":25,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'gradient'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-7d6ba2cc71d8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../deep-learning-from-scratch/common'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradient'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def softmax(x):\n","    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n","    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n","\n","def cross_entropy_error(y, t):\n","    if y.ndim == 1:\n","        t = t.reshape(1, t.size)\n","        y = y.reshape(1, y.size)\n","    batch_size = y.shape[0]\n","    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n","\n","class TwoLayerNet:\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","    def predict(self, x):\n","        W1, W2 = self.params['W1'], self.params['W2']\n","        b1, b2 = self.params['b1'], self.params['b2']\n","        a1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(a1)\n","        a2 = np.dot(z1, W2) + b2\n","        y = softmax(a2)\n","        return y\n","\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        return cross_entropy_error(y, t)\n","\n","    def numerical_gradient(self, x, t):\n","        loss_W = lambda W: self.loss(x, t)\n","        grads = {}\n","        for key in ('W1', 'b1', 'W2', 'b2'):\n","            grads[key] = self.numerical_gradient_1d(loss_W, self.params[key])\n","        return grads\n","\n","    def numerical_gradient_1d(self, f, x):\n","        h = 1e-4\n","        grad = np.zeros_like(x)\n","        it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","        while not it.finished:\n","            idx = it.multi_index\n","            tmp_val = x[idx]\n","            x[idx] = tmp_val + h\n","            fxh1 = f(x)\n","            x[idx] = tmp_val - h\n","            fxh2 = f(x)\n","            grad[idx] = (fxh1 - fxh2) / (2*h)\n","            x[idx] = tmp_val\n","            it.iternext()\n","        return grad\n","\n","    def gradient(self, x, t):\n","        W1, W2 = self.params['W1'], self.params['W2']\n","        b1, b2 = self.params['b1'], self.params['b2']\n","        grads = {}\n","\n","        batch_num = x.shape[0]\n","\n","        # forward\n","        a1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(a1)\n","        a2 = np.dot(z1, W2) + b2\n","        y = softmax(a2)\n","\n","        # backward\n","        dy = (y - t) / batch_num\n","        grads['W2'] = np.dot(z1.T, dy)\n","        grads['b2'] = np.sum(dy, axis=0)\n","\n","        da1 = np.dot(dy, W2.T)\n","        dz1 = sigmoid(a1) * (1 - sigmoid(a1)) * da1\n","        grads['W1'] = np.dot(x.T, dz1)\n","        grads['b1'] = np.sum(dz1, axis=0)\n","\n","        return grads\n","\n","# 데이터 생성 (MNIST 대신 랜덤 데이터 사용)\n","x_train = np.random.rand(100, 784)  # 100개의 784차원 입력\n","t_train = np.eye(10)[np.random.choice(10, 100)]  # 100개의 원-핫 인코딩된 레이블\n","\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","x_batch = x_train[:3]\n","t_batch = t_train[:3]\n","\n","grad_numerical = network.numerical_gradient(x_batch, t_batch)\n","grad_backprop = network.gradient(x_batch, t_batch)\n","\n","# 각 가중치의 차이의 절댓값을 구한 후, 그 절댓값들의 평균을 구한다\n","for key in grad_numerical.keys():\n","    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n","    print(key + \":\" + str(diff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BqWvfRZ8O6_v","executionInfo":{"status":"ok","timestamp":1728829503822,"user_tz":-540,"elapsed":11143,"user":{"displayName":"송여경","userId":"16440594923547462791"}},"outputId":"8761499c-b3b7-4921-852f-7e2dcb2453da"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["W1:5.23646383776392e-10\n","b1:8.911652947274925e-10\n","W2:7.013852240461694e-08\n","b2:1.4023829454368196e-07\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tNsrPxcePqyx"},"execution_count":null,"outputs":[]}]}